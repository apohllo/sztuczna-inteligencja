{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresja liniowa i logistyczna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wstęp\n",
    "\n",
    "![A group of people on Titanic looking at an iceberg.](titanic.png \"Stable diffusion image: A photograph of Titanic crushing with an iceberg made from a matrix\")\n",
    "\n",
    "\n",
    "Celem laboratorium jest zapoznanie z najprostszymi narzędziami do predykcji na podstawie danych - regresją liniową i logistyczną. \n",
    "Zapoznasz się na nim z następującymi tematami:\n",
    "* przygotowaniem danych, w szczególności z:\n",
    "  * ładowaniem danych,\n",
    "  * typami danych,\n",
    "  * obsługą wartości brakujących,\n",
    "  * oceną przydatności atrybutów,\n",
    "  * skalowaniem wartości;\n",
    "* regresją liniową, w szczególności z:\n",
    "  * podziałem zbioru na część treningową i testową,\n",
    "  * oceną jakości modelu,\n",
    "  * walidacją skrośną,\n",
    "  * wyszukiwaniem hiperparametrów;\n",
    "* regresją logistyczną, w szczególności z:\n",
    "  * różnymi rodzajami błędów klasyfikacji,\n",
    "  * problemem przeuczenia, niedouczenia oraz metodami regularyzacji modelu.\n",
    "\n",
    "Na pierwszych zajęciach możesz korzystać ze środowiska Google Colab i zdalnego środowiska obliczeniowego. Jeżeli interesuje Cię skonfigurowanie Pythona u siebie, to niezbędne informacje są podane w sekcji \"Konfiguracja własnego komputera\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wykorzystywane biblioteki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na zajęciach korzystać będziesz z kilku popularnych bibliotek do Pythona, które umożliwiają klasyfikację danych, ich wizualizację czy preprocessing. Są to:\n",
    "1. [numpy](https://numpy.org/) - klasyczna bibliotek do wykonywania obliczeń macierzowych. Pozwala na efektywne przeprowadzanie obliczeń naukowych (np. na macierzach). Dobrze współgra z biblioteką pandas,\n",
    "1. [pandas](https://pandas.pydata.org/) - narzędzie do analizy danych, ich strukturyzowania oraz manipulacji na nich,\n",
    "1. [sklearn](https://scikit-learn.org/stable/) - narzędzie do przeprowadzania klasyfikacji, regresji, clusteringu itp. Biblioteka ta jest dość rozbudowana i pozwala także na mapowanie danych czy redukcję wymiarów. Więcej informacji znajdziesz w podanym linku,\n",
    "1. [missingno](https://pypi.org/project/missingno/) - narzędzie do wizualizacji kompletności danych (brakujących wartości),\n",
    "1. [seaborn](https://seaborn.pydata.org/) - kompleksowe narzędzie do wizualizacji danych jako takich. Pozwala na stworzenie bardzo szerokiej gamy wykresów w zależności od potrzeb.\n",
    "\n",
    "Zostały tutaj pominięte pewne standardowe biblioteki jak np. os czy matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wykorzystanie Google Colab\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/apohllo/sztuczna-inteligencja/blob/master/lab1/lab_1_introduction.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konfiguracja własnego komputera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeżeli korzystasz z własnego komputera, to musisz zainstalować trochę więcej bibliotek (Google Colab ma je już zainstalowane). Najlepiej używać Pythona 3.9, z którym laboratorium było testowane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anaconda\n",
    "\n",
    "Jeżeli korzystasz z Anacondy (możesz uruchomić w terminalu):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge --yes pandas scikit-learn matplotlib missingno imbalanced-learn lightgbm shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### venv\n",
    "\n",
    "Jeżeli używasz zwykłego venv'a (**zdecydowanie niezalecane, szczególnie na Windowsie**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --yes pandas scikit-learn matplotlib missingno imbalanced-learn lightgbm shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W przypadku własnego komputera, jeżeli instalowałeś z terminala, pamiętaj, aby zarejestrować aktualne środowisko wirtualne jako kernel (środowisko uruchomieniowe) dla Jupyter Notebooka. Wybierz go jako używany kernel w menu na górze notebooka (nazwa jak w komendzie poniżej)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ipython kernel install --user --name \"PSI\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przygotowanie danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ładowanie danych tabelarycznych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeżeli pracujesz na Google Colab, zacznij od przeniesienia dwóch plików CSV, które zostały dołączone do laboratorium (`titanic.csv` oraz `titanic_test.csv`), do folderu `/content`. Nie musisz ich umieszczać w `/content/sample_data` - ważne, aby znalazły się w `/content`. Jeżeli pracujesz lokalnie, to wystarczy, że pliki te będą obok tego notebooka.\n",
    "\n",
    "Pliki te to dwa zbiory, jeden jest treningowy (czyli z etykietą klasy), a drugi tych etykiet nie posiada. Celem jest oszacowanie na podstawie dostępnych danych tabelarycznych, czy dany pasażer Titanica przeżył katastrofę (etykieta ma wtedy wartość 1), czy miał mniej szczęścia. Dokładny zestaw cech, którymi będziemy dysponować, omówimy sobie w dalszej części laboratorium.\n",
    "\n",
    "Wczytajmy dane `titanic.csv` do zmiennej `train_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"titanic.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zobaczmy jakie dane znajdują się w naszej tabeli. Wykorzystajmy do tego metodę `info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Szczegółowy opis znaczenia kolumn znajdziesz na [pod linkiem](https://www.kaggle.com/competitions/titanic/data?select=train.csv). Zapoznaj się z akapitem **Data Dictionary**. \n",
    "\n",
    "## Wstępna analiza danych\n",
    "\n",
    "W przytłaczającej większości przypadków, zanim zaczniesz robić jakąkolwiek predykcję czy analizę danych, dobrze jest zapoznać się z nimi, z ich kodowaniem i znaczeniem. Kolejnym istotnym aspektem jest typ danych. Otóż nie każdy klasyfikator nadaje się do każdego typu.\n",
    "\n",
    "Wyświetlmy teraz kilka przykładowych rekordów z samej góry korzystając z metody `head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeżeli potrzebujesz szybko stwierdzić, ile dane zawierają rekordów i kolumn, pomocna okazuje się opcja `shape`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dane kategoryczne\n",
    "\n",
    "Już możemy wysnuć pierwsze wnioski i zauważyć pierwszy problem. Istnieją dwa rodzaje danych: kategoryczne (z ang. *categorical data*) oraz numeryczne (z ang. *numerical data*). Ten podział jest bardzo istotny. Dane numeryczne to żadna niespodzianka, po prostu mają swoją wartość, jak np. **Fare**, czyli opłata za rejs. Dane kategoryczne to takie, którym w większości przypadków nie można przyporządkować wartości liczbowej (wyjątkiem są dane kategoryczne uporządkowane).\n",
    "\n",
    "Wyobraź sobie, że klasyfikujesz kolory i masz wartości RGB. Nie możesz ich zakodować jako np.: R = 0, G = 1 i B = 2. Stwierdzasz tym samym, że w jakimś sensie R < G, R < B i G < B. Nie ma powodu tak sądzić. Istnieje jednak pewien wyjątek. Spójrz na kolumnę **Sex**. Z opisu danych wiesz, że przyjmuje ona dokładnie dwie wartości kategoryczne: *Male* oraz *Female*. W takiej sytuacji wolno Ci zakodować te wartości numerycznie jako 0 i 1. Stwierdzasz tym samym, że ktoś jest **male** albo nie jest. Bez straty w ogólnej definicji problemu możesz zakodować odwrotnie i stwierdzić, że ktoś jest **female** albo nie jest.\n",
    "\n",
    "Wykonaj poniższy kod. Zauważ, że takie zakodowanie cechy miało wpływ na zużycie pamięci (`memory usage`). Jak myślisz, dlaczego?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Categorical\n",
    "\n",
    "train_data[\"Sex\"] = Categorical(train_data[\"Sex\"]).codes\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posiadamy jeszcze jedną kolumnę, która może być dla nas istotna, a zawiera nie dwie, tylko trzy wartości kategoryczne. Jest to kolumna **Embarked**, oznaczająca port, w którym dany pasażer wsiadł. Jak już ustaliliśmy, nie można jej zakodować jako np. 0, 1, 2. Można natomiast usunąć kolumnę **Embarked** i stworzyć trzy nowe, zawierające tylko wartości 0 oraz 1, gdzie 1 oznacza, że pasażer wsiadł w danym porcie. Taką technikę nazywamy z ang. *one-hot encoding*.\n",
    "\n",
    "Zastanów się, co nam daje ta technika, z punktu widzenia wykonywania obliczeń na danych?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import get_dummies\n",
    "\n",
    "train_data = get_dummies(data=train_data, columns=[\"Embarked\"])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wartości brakujące"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Niestety, ale nasze dane trenujące nie są kompletne. Możesz się o tym przekonać, wykonując poniższy kod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możesz zauważyć, że w naszych danych 177 rekordów (z 891) posiada brakującą informację na temat wieku. Z kolei w 687 rekordach brakuje informacji o numerze kabiny. Biblioteką, która pozwala na zwizualizowanie tych braków, jest *missingno*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 1 (0.5p.)**\n",
    "\n",
    "Stwórz wykres słupkowy brakujących danych zawartych w `train_data` wykorzystując *missingno*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your_code_here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skupmy się na kolumnie **Cabin**. Nie będzie nam potrzebna w dalszej predykcji. Po pierwsze są to wartości kategoryczne i jako takie niewiele wnoszą (i tak dysponujemy takimi danymi jak klasa czy opłata). Możemy więc usunąć całą kolumnę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns=\"Cabin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z wiekiem (kolumna **Age**) problem jest większy. Danych brakuje w wielu rekordach, ale nie na tyle wielu, aby tę kolumnę usunąć. Co więcej, może ona być istotna w dalszej predykcji. Musimy się więc zastanowić nad strategią rozwiązania tego problemu. \n",
    "\n",
    "Z brakującymi danymi możemy sobie radzić w sposób następujący:\n",
    "1. Usunąć kolumnę, która zawiera brakujące wartości,\n",
    "1. Usunąć wiersze, w których brakuje wartości,\n",
    "1. Zastąpić brakujące wartości innymi, np. średnią z kolumny, medianą albo wielkością stałą,\n",
    "1. Przewidzieć brakujące wartości wykorzystując odpowiedni model uczenia maszynowego.\n",
    "\n",
    "Ustaliliśmy przed chwilą, że w tym przypadku nie interesują nas rozwiązania 1 oraz 2. Spróbujmy rozwiązania numer 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 2 (0.5p.)**\n",
    "\n",
    "Zastąp brakujące dane w kolumnie **Age** średnią z tej kolumny. \n",
    "\n",
    "**UWAGA** - jeśli wykonujesz operację tego rodzaju, to warto zostawić oryginalne dane, np. żeby poeksperymentować z różnymi metodami uzupełniania danych. Tak też należy zrobić w tym przypadku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = train_data.copy(deep=True)\n",
    "# your_code_here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docelowo będziemy chcieli zastosować strategię numer 4, gdyż dysponujemy odpowiednią liczbą przykładów uczących. Zajmiemy się tym w następnej części laboratorium. \n",
    "\n",
    "## Korelacja atrybutów\n",
    "\n",
    "Analizując pozostałe kolumny, można dojść do wniosku, że imię nie powinno mieć znaczenia w predykcji. Numer biletu to dane kategoryczne, których nie zakodujemy numerycznie. Najzwyczajniej nie miałoby sensu generowanie 891 nowych kolumn. W ramach laboratorium dotyczącego przetwarzania języka dowiemy się, jak można tego rodzaju dane wykorzystać, ale w tym laboratorium po prostu je pominiemy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 3 (0.5p.)**\n",
    "\n",
    "Usuń kolumny **Name** oraz **Ticket** ze zbioru trenującego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your_code_here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ale jest jeszcze coś. Pomoże nam w tym macierz korelacji. Wykonaj poniższy kod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import heatmap\n",
    "\n",
    "heatmap(train_data.corr())\n",
    "train_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To, co widzisz to macierz korelacji (pod spodem reprezentacja graficzna). Współczynniki w macierzy korelacji to tzw. współczynniki korelacji [Pearsona](https://www.statisticshowto.com/probability-and-statistics/correlation-coefficient-formula/). Współczynnik ten oznaczamy jako *r* i przyjmuje on wartości z przedziału [-1, 1], gdzie -1 oznacza silną korelację ujemną (wysokim wartościom jednej cechy odpowiadają niskie drugiej lub odwrotnie), a 1 oznacza silną korelację dodatnią (wysokim wartościom jednej cechy odpowiadają wysokie wartości drugiej i odwrotnie). Taka macierz pozwala nam zweryfikować, czy w naszym zbiorze danych nie ma redundancji. Bardzo często korzystamy wówczas z wartości bezwzględnej *r*, gdyż interesuje nas fakt czy korelacja w ogóle jest, czy jej nie ma.\n",
    "\n",
    "W tworzeniu modelu predykcji, najbardziej pożądane cechy posiadają następujące własności:\n",
    "- mają niski współczynnik korelacji z innymi cechami (chcemy, aby kolumny niosły jak najwięcej różnych informacji)\n",
    "- wysoki współczynnik korelacji z klasą, którą chcemy przewidywać (chcemy, aby kolumny z cechami mówiły jak najwięcej o klasie, którą będziemy przewidywać)\n",
    "\n",
    "Analizując powyższe macierze, zauważyć można, że kolumna **PassengerId** nie jest silnie skorelowana w zasadzie z niczym, a w szczególności z **Age** oraz **Survived** (która to kolumna będzie nas później interesować)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns=\"PassengerId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mamy jeszcze problem. Przed zakodowaniem kolumny **Embarked** nie sprawdziliśmy, czy przypadkiem nie brakowało tam jakichś wartości. Jeżeli brakowało, to będziemy mieli wiersze, gdzie w każdej nowej kolumnie **Embarked** (C, Q, S) będzie zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 4 (0.5p.)**\n",
    "\n",
    "Sprawdź, czy ma miejsce sytuacja, w której w danym wierszu **Embarked_C == Embarked_Q == Embarked_S == 0**. Jeżeli liczba takich rekordów jest mała - usuń je ze zbioru `train_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your_code_here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skalowanie wartości\n",
    "\n",
    "Ostatnim elementem preprocessingu danych jest ich skalowanie. Zastanów się, co by się stało, gdyby wartości w jednej kolumnie wynosiły np. `[10000, 100000]`, a w drugiej `[1, 10]`. Często takie zjawisko może powodować zaburzenia w trenowaniu modelu oraz jakości predykcji. Wszakże każdy algorytm w końcu sprowadza się do dodawania, mnożenia, dzielenia itp. Więcej informacji na temat tego, dlaczego skalowanie jest aż tak istotne, możesz znaleźć [tu](https://analyticsindiamag.com/why-data-scaling-is-important-in-machine-learning-how-to-effectively-do-it/).\n",
    "\n",
    "Wykonajmy poniższy kod. Skaluje on wartości numeryczne z kolumn do przedziału `[0, 1]` z wykorzystaniem `MinMaxScaler`. Skalowanie odbywa się osobno dla każdej cechy.\n",
    "\n",
    "**Uwaga**: zawsze zapisuj nazwy kolumn, gdyż funkcja ta zwraca tablicę numpy, pozbawiona jest informacji o nazwach atrybutów. Zauważ też, że operujemy tylko na danych treningowych (w kontekście kolumny **Survived**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas import DataFrame\n",
    "\n",
    "data_columns = train_data.columns\n",
    "scaler = MinMaxScaler()\n",
    "train_data = DataFrame(scaler.fit_transform(train_data))\n",
    "train_data.columns = data_columns\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten podrozdział pokrył kluczowe aspekty przygotowania danych. Ale jest jeszcze jedna rzecz, którą trzeba wiedzieć. Czasami optymalnym rozwiązaniem jest generowanie zupełnie nowych atrybutów (w oparciu o te istniejące) i używanie tych nowych atrybutów w procesie trenowania modelu. Takim algorytmem jest np. [YAGGA](https://docs.rapidminer.com/8.0/studio/operators/modeling/optimization/feature_generation/optimize_by_generation_yagga2.html) (wykorzystywana w innym popularnym środowisku do uczenia maszynowego, jakim jest RapidMinerStudio). Przy czym dla powyższego przykładu wykorzystanie tego algorytmu byłoby nieuzasadnione. Poza tym biblioteka sklearn nie posiada tego algorytmu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresja liniowa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresja liniowa jest jednym z najprostszych modeli predykcyjnych. Nadaje się ona do predykcji danych numerycznych, a więc w naszym przypadku np. do predykcji danych w kolumnie **Age**. Prosta regresja liniowa, dla 1 zmiennej, wyraża się wzorem:\n",
    "\n",
    "$$\n",
    "y = ax + b,\n",
    "$$\n",
    "\n",
    "gdzie *y* to zmienna zależna, *x* to zmienna niezależna, a współczynniki *a* i *b* liczone są wg wzorów opisanych [tu](https://www.vedantu.com/formula/linear-regression-formula), bez wątpienia znanych Ci z algebry liniowej.\n",
    "\n",
    "Pewnym rozwinięciem regresji liniowej jest Wielokrotna Regresja Liniowa (*Multiple Linear Regression*, *MLR*), która pozwala na wykorzystanie więcej niż jednej cechy do predykcji wartości. Stanowi ona de facto kombinację liniową pojedynczych cech. Więcej o tym mechanizmie możesz przeczytać [tu](https://rankia.pl/analizy-gieldowe/co-to-jest-wielokrotna-regresja-liniowa-mlr/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przygotujmy się do naszej pierwszej predykcji. Z całości zbioru `train_data` wyodrębnimy te przykłady, w których nie brakuje danych z kolumny **Age**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_linear = train_data.dropna(inplace=False, subset=[\"Age\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podział na zbiór treningowy i testowy\n",
    "\n",
    "Nasz zbiór `train_data_linear` podzielmy na dwa podzbiory: trenujący (75%) i testowy (25%). Trenujący pozwoli nam utworzyć model regresji liniowej, natomiast testowy - oszacować jej jakość. W tym momencie do predykcji wieku użyjemy tylko cechy **SibSp** (dla przykładu), będzie to więc klasyczna regresja liniowa. Pamiętaj, że wyniki uzyskiwane przez model na danych treningowych nie są wiarygodne. Konieczne jest sprawdzenie, jak model radzi sobie na danych testowych.\n",
    "\n",
    "**Uwaga**: W eksperymentach ustalamy na sztywno wartość parametru `random_state`. [Doczytaj](https://scikit-learn.org/stable/glossary.html#term-random_state), dlaczego wykorzystywany jest ten parametr i co się dzieje, gdy jest on równy zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = train_data_linear[\"SibSp\"]\n",
    "y = train_data_linear[\"Age\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.25, random_state=0, shuffle=True\n",
    ")\n",
    "x_train = x_train.values.reshape(-1, 1)\n",
    "x_test = x_test.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trening modelu regresji\n",
    "\n",
    "Na poniższym przykładzie możesz zobaczyć, jak trenujemy model oraz jak wygląda jego reprezentacja graficzna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "predict = model.predict(x_test)\n",
    "\n",
    "plt.scatter(x_test, y_test, color=\"black\")\n",
    "plt.xlabel(\"SibSp\")\n",
    "plt.ylabel(\"Age\")\n",
    "plt.plot(x_test, predict, color=\"red\", linewidth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ocena jakości modelu\n",
    "\n",
    "Pytanie: skąd wiemy, czy nasz model działa dobrze, czy też źle? W regresji liniowej mamy do tego dwa podstawowe wskaźniki: Współczynnik determinacji (`r2_score`), który pokazuje, jak silna jest korelacja pomiędzy modelem, a próbą (im bliżej 1, tym lepiej), oraz błąd średniokwadratowy (**MSE** - *mean square error*), który pokazuje błąd średniokwadratowy naszego modelu (im bliżej 0, tym lepiej). Wykonaj poniższy kod, aby obliczyć oba te współczynniki dla wytrenowanego modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_test, predict)\n",
    "MSE = mean_squared_error(y_test, predict)\n",
    "print(r2)\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nasza wartość MSE jest przyzwoita, stosunkowo blisko zera. Zauważ natomiast, że współczynnik determinacji jest także bliski zeru. Czy to źle? Cóż, w naszym przypadku istotniejszy jest MSE. To, że nasz model przewiduje raz wiek zbyt duży, a raz zbyt mały, nie jest dla nas aż tak istotne, gdyż różnica od wieku prawdziwego jest niewielka. Pamiętaj jednak, że w przypadku wartości MSE istotna jest też skala (przedział) danych, które przewidujemy. Powyższa wartość MSE nie byłaby aż tak korzystna, gdyby przeskalowana wartość **AGE** wahała się np. w przedziale $[0, 0.03]$. Tak jednak nie jest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(y_test))\n",
    "print(max(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[\"*You can have a very good MSE for a model which has a very poor R-squared. It just means that the your model has a low error when predicting values but there is very little correlation between the variables. These are statistical measures anyway.*\"](https://www.researchgate.net/post/Why_my_regression_model_shows_good_MSE_but_bad_R-squared_value)\n",
    "\n",
    "**Uwaga:** r2 używamy zazwyczaj na zbiorze treningowym. Jeżeli jesteś ciekawy dlaczego, [tu](https://stats.stackexchange.com/questions/348330/should-r2-be-calculated-on-training-data-or-test-data) znajdziesz interesującą dyskusję na ten temat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walidacja skrośna\n",
    "\n",
    "Taki jednorazowy podział na zbiór trenujący i testowy (zwany zresztą z ang. *Split Validation* albo *Holdout*) może jednak dawać przekłamane wyniki, w szczególności, jeśli zbiór danych jest mały. Dlatego do weryfikacji jakości predykcji możemy również użyć walidacji skrośnej (z ang. *Cross Validation*). Walidacja skrośna polega na tym, że całość zbioru trenującego jest dzielona na K równych podzbiorów (tzw. *foldów*). Każdy podzbiór raz jest zbiorem testowym, a wówczas reszta staje się zbiorem trenującym. Koniec końców otrzymujemy więc K wyników, które możemy uśrednić i obliczyć z nich odchylenie standardowe. Spójrz na poniższy przykład."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from statistics import mean, stdev\n",
    "\n",
    "x = x.values.reshape(-1, 1)\n",
    "\n",
    "scores_r2 = cross_val_score(model, x, y, scoring=\"r2\", cv=10)\n",
    "scores_mse = cross_val_score(model, x, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "print(\"mean: \", mean(scores_r2), \" std: \", stdev(scores_r2))\n",
    "print(\"mean: \", mean(scores_mse), \" std: \", stdev(scores_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takie wyniki są znacznie bardziej wiarygodne. Typową liczbą podzbiorów jest 5-10 (zwykle im większy zbiór, tym mniej podzbiorów - aby zaoszczędzić czas).\n",
    "\n",
    "## Wykorzystanie wielu cech\n",
    "\n",
    "Dlaczego mamy korzystać tylko z jednej cechy w naszej predykcji? Spróbujmy nasz model rozbudować. Może zastosowanie wszystkich cech będzie lepszym rozwiązaniem? A może jakiegoś ich podzbioru?\n",
    "\n",
    "Przeanalizuj poniższy kod. Zauważ, że z tymczasowych danych trenujących *x* usunięta zostaje kolumna **Survived**. Jest to konieczne, ponieważ, docelowo (gdy już uzupełnimy **Age**) będzie to kolumna, którą będziemy chcieli przewidywać. Nie chcemy przewidywać danych w **Survived** z użyciem danych **Age** przewidzianych z wykorzystaniem **Survived**, bo to może zaburzyć wyniki predykcji w dalszym etapie naszego laboratorium. \n",
    "\n",
    "## Wyszukiwanie hiperparametrów na siatce\n",
    "\n",
    "Zauważ także, że używamy ekstraktora cech `RFE` (feature selection). Przekazując do niego model, możemy zdecydować ile cech ma on wyekstrahować. Ale my nie chcemy tego robić dla każdej kombinacji cech oddzielnie, wprowadzając ich liczbę \"z palca\". Wolelibyśmy, żeby optymalna liczba tych cech została określona eksperymentalnie.\n",
    "\n",
    "Tutaj z pomocą przychodzi [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Jest to klasa, której najważniejsze parametry to: model, lista parametrów do optymalizowania modelu (właściwa dla danego modelu, RFE posiada jeden istotny parametr (zwany n_features_to_select) oraz krotność podzbiorów. \n",
    "\n",
    "**Uwaga**: doczytaj w dokumentacji co to jest `neg_mean_squared_error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "folds = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "hyper_params = [{\"n_features_to_select\": list(range(1, train_data.shape[1]))}]\n",
    "\n",
    "X = train_data_linear.drop(inplace=False, columns=[\"Age\"]).drop(columns=\"Survived\")\n",
    "model.fit(X, y)\n",
    "model_rfe = RFE(model)\n",
    "\n",
    "model_cv = GridSearchCV(\n",
    "    estimator=model_rfe,\n",
    "    param_grid=hyper_params,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    cv=folds,\n",
    "    verbose=1,\n",
    "    return_train_score=True,\n",
    ")\n",
    "\n",
    "model_cv.fit(X, y)\n",
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wiemy już, że nie wszystkie cechy są tak samo istotne. Razem jest ich 9 (usunęliśmy kolumnę **Survived**), ale dzięki RFE wiemy, że optymalne rozwiązanie otrzymamy z wykorzystaniem ośmiu z nich. Czas użyć trochę nowej wiedzy w praktyce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trening ulepszonego modelu regresji\n",
    "\n",
    "**Zadanie 5 (2p.)**\n",
    "\n",
    "Celem jest zastąpienie wartości NaN z kolumny **Age** w zbiorze `train_data` przewidzianymi wartościami.\n",
    "\n",
    "Wykonaj poniższe czynności:\n",
    "1. Przygotuj tymczasową zmienną `y_train` zawierającą dane z kolumny **Age** ze zbioru `train_data_linear`.\n",
    "1. Przygotuj zmienną `x_train` zawierającą wszystkie kolumny z `train_data_linear` za wyjątkiem kolumn **Survived** oraz **Age**.\n",
    "1. Przygotuj zmienną `x_test` na podstawie pierwotnego zbioru trenującego: `train_data`. `x_test` powinno zawierać wszystkie te rekordy, gdzie **Age** jest NaN. Po wyselekcjonowaniu tych rekordów, usuń z `x_test` kolumny **Age** oraz **Survived**.\n",
    "1. Wytrenuj model regresji liniowej na podstawie danych (`x_train, y_train`), z wykorzystaniem `RFE` z ustaloną liczbą cech równą 8 (wybrane na podstawie poprzedniej analizy).\n",
    "1. Wykorzystaj model do predykcji wartości **Age** dla zbioru `x_test`, wyniki zapisz w zmiennej `predict`.\n",
    "1. W oryginalnym zbiorze danych `train_data`, zastąp wartości NaN z kolumny **Age** wartościami ze zmiennej `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = # your_code_here\n",
    "X_train = # your_code_here\n",
    "X_test = # your_code_here\n",
    "\n",
    "# your_code_here\n",
    "\n",
    "predict = # your_code_here\n",
    "\n",
    "train_data.loc[train_data[\"Age\"].isna(), \"Age\"] = predict\n",
    "\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tak oto udało nam się poradzić z brakującymi wartościami w kolumnie **Age**. Nasz zbiór `train_data` jest kompletny i może posłużyć jako treningowy do zadania klasyfikacji związanego z kolumną **Survived**.\n",
    "\n",
    "## Wczytanie danych testowych\n",
    "\n",
    "Zanim zajmiemy się jednak klasyfikacją, musimy wczytać dane testowe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 6 (2p.)**\n",
    "\n",
    "Wykonaj poniższe czynności:\n",
    "1. Wczytaj dane testowe `titanic_test.csv`.\n",
    "1. Zapoznaj się z danymi, sprawdź, czy brakuje kolumn/rekordów.\n",
    "1. Opracuj dane testowe tak, aby była możliwa predykcja klasy **Survived**. W szczególności pamiętaj o:\n",
    "* przekonwertowaniu odpowiednich kolumn z kategorycznych na numeryczne,\n",
    "* usunięciu odpowiednich kolumn,\n",
    "* odpowiednim przeskalowaniu danych,\n",
    "* uzupełnieniu brakujących wartości **Age**, wykorzystaj już wytrenowany klasyfikator,\n",
    "* podejmij decyzję, co zrobić z brakującą wartością **Fare**.\n",
    "\n",
    "Gdy wykonasz wszystko powyższe, zwizualizuj dane testowe z użyciem metody `matrix()` z biblioteki missingno. W danych testowych nie powinno być wartości brakujących.\n",
    "\n",
    "Pamiętaj o nazwach kolumn, w zbiorze trenującym i testowym muszą być takie same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from missingno import matrix\n",
    "\n",
    "# your_code_here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresja logistyczna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresja logistyczna jest modelem, który pozwala na przewidywanie wartości zmiennych dychotomicznych (binarnych), w oparciu o jedną lub większą ilość cech. Funkcją bazową regresji logistycznej jest funkcja logistyczna:\n",
    "\n",
    "$$\n",
    "y = \\sigma(x) = \\frac{1}{1 + e^{-(ax + b)}}\n",
    "$$\n",
    "\n",
    "Funkcja ta jest bardzo podobna do regresji liniowej (współczynniki, których uczy się model to $a$ oraz $b$), ale wartości tej funkcji ograniczone są do zbioru $[0,1]$. Dzięki temu można bardzo łatwo zmapować te wartości na zbiór dwuelementowy: 0 i 1, wygodny do klasyfikacji - jeśli wartość funkcji jest > 0.5, to mapowana jest ona na 1, w przeciwnym razie na 0. Bardzo ciekawe podsumowanie teoretycznych podstaw regresji logistycznej znajdziesz [tu](https://philippmuens.com/logistic-regression-from-scratch).\n",
    "\n",
    "Zmienne dychotomiczne to inaczej zmienne, które przyjmują jedynie dwie wartości. Przykładem jest nasza kolumna **Survived** z danych trenujących. Podzielmy więc zbiór trenujący (zawierający etykiety klasy) na podzbiory do trenowania i testowania modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(inplace=False, columns=[\"Survived\"])\n",
    "y = train_data[\"Survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=0, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ocena poprawności klasyfikacji\n",
    "\n",
    "Wytrenujmy nasz pierwszy model i oszacujmy jego dokładność."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "74% - nieźle, ale może da się ten wynik poprawić. Problem, którym teraz się zajmujemy to problem klasyfikacji. W problemach klasyfikacji mamy dwie główne miary jakości modelu. Jest to dokładność (z ang. *accuracy*) albo tzw. AUC (z ang. *Area Under [ROC] Curve*).\n",
    "Dokładność jest dość intuicyjną miarą, gdyż jest to liczba poprawnie zaklasyfikowanych przykładów (z obu kategorii), podzielona przez liczbę wszystkich przykładów podlegających klasyfikacji:\n",
    "\n",
    "$$\n",
    "Acc = \\frac{TP+TN}{TP+TN+FP+FN},\n",
    "$$\n",
    "\n",
    "gdzie: \n",
    "\n",
    "* $TP$ (true positives) - liczba pozytywnych przypadków (np. osób, które przeżyły katastrofę) zaklasyfikowanych poprawnie,\n",
    "* $TN$ (true negatives) - liczba negatywnych przypadków (np. osób, które nie przeżyły katastrofy) zaklasyfikowanych poprawnie,\n",
    "* $FP$ (false positives) - liczba pozytywnych przypadków, zaklasyfikowanych błędnie,\n",
    "* $FN$ (false negatives) - liczba negatywnych przypadków, zaklasyfikowanych błędnie.\n",
    "\n",
    "Dokładności używamy, gdy klasy rozłożone są w miarę równomiernie, a AUC, gdy jedna klasa jest dominująca. Sprawdźmy, jak jest w naszym przypadku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_0 = y[y == 0].size\n",
    "y_1 = y[y == 1].size\n",
    "print(\"0:\", y_0)\n",
    "print(\"1:\", y_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uznajmy, że zbiór ten jest umiarkowanie zbalansowany. Wybierzmy więc `accuracy` jako `scoring`. `roc_auc` wykorzystamy w następnym laboratorium, gdzie zbiór danych będzie znacznie bardziej niezbalansowany.\n",
    "\n",
    "**Zadanie 7 (1p.)**\n",
    "\n",
    "Ustal optymalną liczbę cech do predykcji klasy **Survived**. Skorzystaj z `RFE`, `GridSearchCV` oraz 10-krotnej walidacji skrośnej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = [{\"n_features_to_select\": list(range(1, train_data.shape[1]))}]\n",
    "model_rfe = # your_code_here\n",
    "\n",
    "# your_code_here\n",
    "\n",
    "model_cv = # your_code_here\n",
    "\n",
    "model_cv.fit(X_train, y_train)\n",
    "model_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posiadając liczbę cech, ustalmy jaki zestaw parametrów regresji logistycznej ([zobacz parametry](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)) jest optymalny dla naszego problemu. Jako solvera użyjemy modelu *saga*. Jest on szybki i wspiera regularyzację Elastic Net ([zobacz definicję](https://en.wikipedia.org/wiki/Elastic_net_regularization)).\n",
    "\n",
    "## Przeuczenie\n",
    "\n",
    "W trakcie trenowania modelu może dojść do sytuacji, w której zostanie on przeuczony (z ang. *overfitting*). Gdy to się wydarzy, model może mieć bardzo dokładne wyniki, gdy zastosujemy go na danych, które już widział na etapie trenowania. Takie szacowanie jakości modelu jest oczywiście błędem metodologicznym. Przeuczenie modelu jest bardzo istotnym problemem w sztucznej inteligencji i isnieje szereg metod, służących zapobieganiu tego zjawiska. Jedną z nich jest regularyzacja - do globalnej funkcji błędu dodawane są \"kary\": `l1` oraz `l2`, które stanowią miary wielkości parametrów obliczonych w trakcie treningu. Obie te wartości są tak naprawdę normami (odpowiednio `l1` i `l2`) wektorów wag modelu przeskalowane przez określoną wartość (w sklearn określoną jako `C`). Dodawanie tych kar ma zabiec przeuczeniu. Jak słusznie możesz się spodziewać, zbyt duże kary spowoduję z kolei niedouczenie (ang. *underfitting*). Więcej o konstrukcji i zastosowaniach regularyzacji `l1` i `l2` przeczytać możesz [tu](https://towardsdatascience.com/intuitions-on-l1-and-l2-regularisation-235f2db4c261)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 8 (1p.)**\n",
    " \n",
    " Dowiedz się, jaki zestaw parametrów dla naszego problemu jest optymalny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    \"estimator__solver\": [\"saga\"],\n",
    "    \"estimator__C\": [0.001, .009, 0.01, .09, 1, 5],\n",
    "    \"estimator__penalty\": [\"l1\", \"l2\"],\n",
    "    \"estimator__intercept_scaling\": [0.01, 0.1, 1., 10., 20.],\n",
    "    \"estimator__max_iter\": [1000],\n",
    "    \"n_features_to_select\": [7]\n",
    "    }\n",
    "model_cv = # your_code_here\n",
    "\n",
    "print(model_cv.best_params_)\n",
    "print(model_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 9 (1p.)**\n",
    "\n",
    "Wytrenuj optymalny model (parametry dobierz na podstawie poprzednich zadań) oraz dokonaj predykcji brakujących wartości klasy **Survived** dla zbioru `titanic_test.csv`. Wyniki zwizualizuj na wykresie słupkowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your_code_here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytania kontrolne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**1p.**)\n",
    "\n",
    "1. Co zrobić z kolumną, która zawiera wartości od \"A\" do \"D\", a powinna zostać wykorzystana przez model?\n",
    "1. Jakie są sposoby radzenia sobie z danymi brakującymi?\n",
    "1. Jak nazwiesz typ wartości dla kolumny, która zawiera tylko i wyłącznie liczby 13 oraz 17?\n",
    "1. Czy stosowanie jednorazowego podziału zbioru na testowy i trenujący jest zawsze niezalecane? Jaka jest inna metoda?\n",
    "1. Czy każda cecha w modelu jest istotna? Jakie znasz metody wybierania podzbiorów cech?\n",
    "1. Jak oszacować skuteczność modelu, który dokonuje predykcji gatunku zwierzęcia, a jak modelu, który przewiduje kurs akcji giełdowych?\n",
    "1. Jakiej wartości korelacji spodziewać się dla danych typu kraj pochodzenia - język, a jakich dla problemu typu *predator - prey*?\n",
    "1. Jakich modeli użyć dla obu problemów opisanych w punkcie wyżej?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie dodatkowe *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2p.)**\n",
    "\n",
    "Poniższe zadanie jest dodatkowe, nie musisz go wykonać.\n",
    "\n",
    "W tym laboratorium rozważyliśmy dwa rodzaje regresji: liniową i logistyczną. W bibliotece sklearn istnieje jednak kilka innych typów liniowych modeli ([Linear classifiers](https://scikit-learn.org/stable/modules/classes.html?highlight=sklearn+linear_model#module-sklearn.linear_model)). Sprawdź czy dla problemu wieku (**Age**) i/lub klasy **Survived** dasz radę uzyskać wyższą skuteczność niż dla modeli zaproponowanych w laboratorium. Jeżeli Ci się to uda, oszacuj, czy różnica/różnice są znaczące z punktu widzenia statystycznego.\n",
    "\n",
    "Dodatkowo, jeżeli wyżej wspomniane tematy są dla Ciebie interesujące, zapoznaj się z materiałami dodatkowymi: [train-valid-test split](https://mlu-explain.github.io/train-test-validation/), [ROC & AUC](https://mlu-explain.github.io/roc-auc/), [Regresja logistyczna](https://mlu-explain.github.io/logistic-regression/), [MLU Explain](https://mlu-explain.github.io/linear-regression/) oraz [regularyzacja L1 i L2](https://sebastianraschka.com/faq/docs/regularization-linear.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
